{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cbd5d33-eb5d-4479-916c-9a069a7707da",
   "metadata": {
    "id": "7cbd5d33-eb5d-4479-916c-9a069a7707da"
   },
   "source": [
    "# Final Experimentation Notebook\n",
    "\n",
    "In terms of the implementation of these two metrics, the maintainers of TensorFlow\n",
    "provide a convenient out-of-the-box implementation of both IS and FID in their TF-\n",
    "GAN package. In terms of the evaluation process, I first will split the CIFAR-10 data\n",
    "into train and test as the test data is needed for evaluation purposes with FID. I will then\n",
    "train 4 GANs and 4 VAEs on the training data. The models that will be tested will use\n",
    "the following architectures: transposed convolution, upscaling convolution, conditional\n",
    "transposed convolution, and conditional upscaling convolution. In terms of model size,\n",
    "all GANs and VAEs respectively will be very similar if not the same size to prevent bias\n",
    "from being introduced. Lastly, all 8 models will generate 200 to 400 random images and\n",
    "will be processed using both FID and IS\n",
    "\n",
    "In summary\n",
    "- Will be evaluating the performance of 8 models\n",
    "   - Transposed convolution GAN / VAE\n",
    "   - Upscaling convolution GAN / VAE\n",
    "   - Transposed convolution conditional GAN / VAE\n",
    "   - Upscaling convolution conditional GAN / VAE\n",
    "- For each class of model (GAN or VAE) will try to force the architecture to be the same\n",
    "- Will use FID and IS to evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad77393a-a737-4b84-82fc-b18b8fd106e2",
   "metadata": {
    "id": "ad77393a-a737-4b84-82fc-b18b8fd106e2"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0d6c21-475d-4ecd-a091-bc7fe2f2a620",
   "metadata": {
    "id": "6f0d6c21-475d-4ecd-a091-bc7fe2f2a620"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195ec4e0-2783-4be8-8302-e2042a86c695",
   "metadata": {
    "id": "195ec4e0-2783-4be8-8302-e2042a86c695"
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb0fea-54c5-4bb0-afc2-d64e71a66b61",
   "metadata": {
    "id": "1dfb0fea-54c5-4bb0-afc2-d64e71a66b61",
    "tags": []
   },
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5496547b-5cd4-46fc-a064-2c38ad4372a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5496547b-5cd4-46fc-a064-2c38ad4372a7",
    "outputId": "df4e2cf5-d318-44d3-fa68-ee7432da5cdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 12:53:34.403369: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-17 12:53:34.965311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79111 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (60000, 32, 32, 3)\n",
      "Shape of training labels: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "all_images = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_images = all_images.astype(\"float32\") / 255.0\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_images.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630956e-fc1b-436b-addc-95b6752c6cea",
   "metadata": {
    "id": "7630956e-fc1b-436b-addc-95b6752c6cea",
    "tags": []
   },
   "source": [
    "# Transposed Convolution Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cefffe-c6dc-4ac5-be60-b01b096368de",
   "metadata": {
    "id": "87cefffe-c6dc-4ac5-be60-b01b096368de",
    "tags": []
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b420a27-64ef-4eea-934c-fea07b9e3c7d",
   "metadata": {
    "id": "4b420a27-64ef-4eea-934c-fea07b9e3c7d"
   },
   "outputs": [],
   "source": [
    "latent_dim = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d0c0686-89da-46a3-8a60-b72070602a78",
   "metadata": {
    "id": "3d0c0686-89da-46a3-8a60-b72070602a78"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((32, 32, 3)),\n",
    "     \n",
    "        layers.Conv2D(62, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "     \n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((latent_dim,)),\n",
    "        layers.Dense(4 * 4 * latent_dim * 2),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Reshape((4, 4, latent_dim * 2)),\n",
    "     \n",
    "        layers.Conv2DTranspose(192, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2DTranspose(96, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2DTranspose(48, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29b816d-46aa-40dc-9004-a45a277ab656",
   "metadata": {
    "id": "b29b816d-46aa-40dc-9004-a45a277ab656"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb3b2242-699e-461a-9a17-2a918773d446",
   "metadata": {
    "id": "cb3b2242-699e-461a-9a17-2a918773d446"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                random_latent_vectors = tf.random.normal(shape=(49, 110))\n",
    "                generated_image = gan1.generator(random_latent_vectors)\n",
    "                generated_image.numpy()\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[i])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_und_trans_conv_gan.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f72f6f15-2a08-472e-b0f2-a0e8a12c6b75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f72f6f15-2a08-472e-b0f2-a0e8a12c6b75",
    "outputId": "12f7b7f9-09c3-4f4e-9ed9-600bfe21cf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 6s 9ms/step - d_loss: 0.6178 - g_loss: 1.0355\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6653 - g_loss: 0.8726\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6648 - g_loss: 0.8688\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6681 - g_loss: 0.8660\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6802 - g_loss: 0.8314\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6763 - g_loss: 0.8295\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6768 - g_loss: 0.8358\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6716 - g_loss: 0.8475\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6624 - g_loss: 0.8933\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6663 - g_loss: 0.8741\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 6s 9ms/step - d_loss: 0.6743 - g_loss: 0.8526\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6753 - g_loss: 0.8504\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6752 - g_loss: 0.8504\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6719 - g_loss: 0.8502\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6699 - g_loss: 0.8767\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6650 - g_loss: 0.8764\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6635 - g_loss: 0.9057\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6627 - g_loss: 0.8836\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6686 - g_loss: 0.8656\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6767 - g_loss: 0.8351\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 9ms/step - d_loss: 0.6792 - g_loss: 0.8284\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6795 - g_loss: 0.8136\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6820 - g_loss: 0.8144\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6815 - g_loss: 0.8142\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6818 - g_loss: 0.8091\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6826 - g_loss: 0.8095\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6835 - g_loss: 0.8014\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6849 - g_loss: 0.7994\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6856 - g_loss: 0.7920\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6866 - g_loss: 0.7881\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 6s 9ms/step - d_loss: 0.6859 - g_loss: 0.7935\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6852 - g_loss: 0.7853\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6865 - g_loss: 0.7855\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6868 - g_loss: 0.7843\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6867 - g_loss: 0.7849\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6861 - g_loss: 0.7820\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6873 - g_loss: 0.7813\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6863 - g_loss: 0.7820\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6875 - g_loss: 0.7825\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6858 - g_loss: 0.7788\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 9ms/step - d_loss: 0.6863 - g_loss: 0.7811\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6860 - g_loss: 0.7780\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7780\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6877 - g_loss: 0.7775\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6863 - g_loss: 0.7803\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6868 - g_loss: 0.7774\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6860 - g_loss: 0.7767\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7781\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6865 - g_loss: 0.7788\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6877 - g_loss: 0.7771\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 5s 9ms/step - d_loss: 0.6870 - g_loss: 0.7742\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6860 - g_loss: 0.7768\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6865 - g_loss: 0.7784\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7765\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7762\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6866 - g_loss: 0.7752\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7779\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6864 - g_loss: 0.7763\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6862 - g_loss: 0.7760\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6862 - g_loss: 0.7755\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 6s 9ms/step - d_loss: 0.6862 - g_loss: 0.7768\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6867 - g_loss: 0.7757\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6858 - g_loss: 0.7760\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6867 - g_loss: 0.7749\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6859 - g_loss: 0.7757\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6856 - g_loss: 0.7739\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6859 - g_loss: 0.7777\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6860 - g_loss: 0.7753\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6851 - g_loss: 0.7784\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6852 - g_loss: 0.7779\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 9ms/step - d_loss: 0.6849 - g_loss: 0.7770\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6848 - g_loss: 0.7796\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6845 - g_loss: 0.7813\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6844 - g_loss: 0.7793\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6838 - g_loss: 0.7810\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6833 - g_loss: 0.7791\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6833 - g_loss: 0.7831\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6837 - g_loss: 0.7831\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6820 - g_loss: 0.7817\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6820 - g_loss: 0.7834\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 5s 9ms/step - d_loss: 0.6826 - g_loss: 0.7861\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6826 - g_loss: 0.7859\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6818 - g_loss: 0.7863\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6817 - g_loss: 0.7862\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6808 - g_loss: 0.7872\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6802 - g_loss: 0.7893\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6801 - g_loss: 0.7893\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6797 - g_loss: 0.7909\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6797 - g_loss: 0.7918\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6783 - g_loss: 0.7959\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 6s 10ms/step - d_loss: 0.6777 - g_loss: 0.7945\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6776 - g_loss: 0.7943\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6783 - g_loss: 0.7960\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6774 - g_loss: 0.7963\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6771 - g_loss: 0.7969\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6766 - g_loss: 0.7987\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6758 - g_loss: 0.7991\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6754 - g_loss: 0.8001\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6758 - g_loss: 0.8025\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 5s 8ms/step - d_loss: 0.6750 - g_loss: 0.8024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b696eab1cd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gan1 = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan1.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "gan1.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08a1f6d-1117-49b6-af9c-e3cb02fcb55b",
   "metadata": {
    "id": "d08a1f6d-1117-49b6-af9c-e3cb02fcb55b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.49180132]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def sampleGan():\n",
    "    random_latent_vectors = tf.random.normal(shape=(1, 110))\n",
    "    generated_image = gan1.generator(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    plt.imshow(generated_image[0])\n",
    "    plt.show()\n",
    "    print(gan1.discriminator(generated_image))\n",
    "sampleGan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8e461ed-4396-4afd-b2ff-24d9bafae7a2",
   "metadata": {
    "id": "a8e461ed-4396-4afd-b2ff-24d9bafae7a2"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def save_plot():\n",
    "    random_latent_vectors = tf.random.normal(shape=(49, 110))\n",
    "    generated_image = gan1.generator(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    for i in range(49):\n",
    "        # define subplot\n",
    "        pyplot.subplot(7, 7, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(generated_image[i])\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot.png'\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "save_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca4c0c47-1038-4cd1-af85-0abc0fc596d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: un_trans_conv_gan/assets\n"
     ]
    }
   ],
   "source": [
    "gan1.generator.save(\"un_trans_conv_gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec6dd69-a9d8-469a-a27f-1d1ea10d42e5",
   "metadata": {
    "id": "bec6dd69-a9d8-469a-a27f-1d1ea10d42e5",
    "tags": []
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2a018e3-eb1c-45b3-b1f9-6510113dd378",
   "metadata": {
    "id": "f2a018e3-eb1c-45b3-b1f9-6510113dd378"
   },
   "outputs": [],
   "source": [
    "latent_dim=110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "788888ad-1289-4a41-a827-ca98e8987b82",
   "metadata": {
    "id": "788888ad-1289-4a41-a827-ca98e8987b82"
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(encoder_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(8 * 8 * 32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 8, 32))(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(96, (4, 4), strides=(2, 2), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = layers.Conv2D(3, (4, 4), padding='same', activation=\"sigmoid\", use_bias=False)(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72a19337-e4fc-4d1e-af2a-78029569b7d4",
   "metadata": {
    "id": "72a19337-e4fc-4d1e-af2a-78029569b7d4"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af2e5489-da75-4e79-a442-2f35c8dc00e4",
   "metadata": {
    "id": "af2e5489-da75-4e79-a442-2f35c8dc00e4"
   },
   "outputs": [],
   "source": [
    "class VAEMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                random_latent_vectors = tf.random.normal(shape=(49, self.latent_dim))\n",
    "                generated_image = vae1.decoder(random_latent_vectors)\n",
    "                generated_image.numpy()\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[i])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_und_trans_conv_vae.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9736294f-0f93-4d48-9c9f-327bb008caed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9736294f-0f93-4d48-9c9f-327bb008caed",
    "outputId": "899af6fa-7d46-4a0a-d363-798fad621435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 661.3050 - reconstruction_loss: 644.6620 - kl_loss: 10.8329\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 649.5977 - reconstruction_loss: 637.9694 - kl_loss: 10.7615\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 645.3266 - reconstruction_loss: 634.2410 - kl_loss: 10.6174\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 642.1618 - reconstruction_loss: 631.9382 - kl_loss: 10.1601\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 640.6592 - reconstruction_loss: 630.7784 - kl_loss: 9.8709\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 639.4352 - reconstruction_loss: 629.5911 - kl_loss: 9.9377\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 638.5654 - reconstruction_loss: 628.7861 - kl_loss: 9.9879\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 637.9788 - reconstruction_loss: 628.1715 - kl_loss: 10.0115\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 637.3160 - reconstruction_loss: 627.4072 - kl_loss: 10.1076\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 636.6662 - reconstruction_loss: 626.5397 - kl_loss: 10.2010\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 635.9243 - reconstruction_loss: 625.9667 - kl_loss: 10.1554\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 635.5372 - reconstruction_loss: 625.7903 - kl_loss: 10.1068\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 635.3931 - reconstruction_loss: 625.5552 - kl_loss: 10.1212\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 635.2125 - reconstruction_loss: 625.3716 - kl_loss: 10.1489\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 635.0160 - reconstruction_loss: 624.7107 - kl_loss: 10.4066\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 634.0918 - reconstruction_loss: 623.6500 - kl_loss: 10.7828\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 633.9904 - reconstruction_loss: 623.4515 - kl_loss: 10.8105\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 633.8201 - reconstruction_loss: 623.1710 - kl_loss: 10.8973\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 633.4243 - reconstruction_loss: 622.6835 - kl_loss: 10.9836\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 633.0345 - reconstruction_loss: 622.4370 - kl_loss: 10.9984\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 632.9901 - reconstruction_loss: 622.3483 - kl_loss: 11.0115\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.8706 - reconstruction_loss: 622.2564 - kl_loss: 11.0300\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.8781 - reconstruction_loss: 622.1963 - kl_loss: 11.0209\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.7432 - reconstruction_loss: 622.1250 - kl_loss: 11.0318\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.6999 - reconstruction_loss: 622.0513 - kl_loss: 11.0490\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.6464 - reconstruction_loss: 621.9991 - kl_loss: 11.0617\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.6542 - reconstruction_loss: 621.9764 - kl_loss: 11.0639\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.5624 - reconstruction_loss: 621.8510 - kl_loss: 11.0651\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.5109 - reconstruction_loss: 621.8178 - kl_loss: 11.0801\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.5134 - reconstruction_loss: 621.7700 - kl_loss: 11.0840\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 632.4802 - reconstruction_loss: 621.7587 - kl_loss: 11.1032\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.3335 - reconstruction_loss: 621.6707 - kl_loss: 11.0942\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.4016 - reconstruction_loss: 621.6271 - kl_loss: 11.1116\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.3135 - reconstruction_loss: 621.5740 - kl_loss: 11.0999\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.2927 - reconstruction_loss: 621.5664 - kl_loss: 11.1315\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.2552 - reconstruction_loss: 621.4991 - kl_loss: 11.1202\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.1868 - reconstruction_loss: 621.4627 - kl_loss: 11.1464\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.2631 - reconstruction_loss: 621.4473 - kl_loss: 11.1289\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 632.1308 - reconstruction_loss: 621.3818 - kl_loss: 11.1395\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.2070 - reconstruction_loss: 621.3528 - kl_loss: 11.1449\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 632.0077 - reconstruction_loss: 621.2968 - kl_loss: 11.1573\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.0998 - reconstruction_loss: 621.2875 - kl_loss: 11.1510\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.0311 - reconstruction_loss: 621.2538 - kl_loss: 11.1620\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.9721 - reconstruction_loss: 621.1934 - kl_loss: 11.1672\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 632.0530 - reconstruction_loss: 621.1921 - kl_loss: 11.1891\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.9881 - reconstruction_loss: 621.1285 - kl_loss: 11.1896\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.9211 - reconstruction_loss: 621.0892 - kl_loss: 11.1938\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.9471 - reconstruction_loss: 621.0852 - kl_loss: 11.1857\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.8032 - reconstruction_loss: 621.0188 - kl_loss: 11.1957\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.8303 - reconstruction_loss: 621.0359 - kl_loss: 11.2163\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 631.7599 - reconstruction_loss: 620.9549 - kl_loss: 11.1973\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.8341 - reconstruction_loss: 620.9585 - kl_loss: 11.2114\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.7924 - reconstruction_loss: 620.9158 - kl_loss: 11.2236\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.7360 - reconstruction_loss: 620.8703 - kl_loss: 11.2197\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.7688 - reconstruction_loss: 620.8732 - kl_loss: 11.2225\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.6729 - reconstruction_loss: 620.8062 - kl_loss: 11.2389\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.7083 - reconstruction_loss: 620.7945 - kl_loss: 11.2523\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.6174 - reconstruction_loss: 620.7814 - kl_loss: 11.2554\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.6095 - reconstruction_loss: 620.7122 - kl_loss: 11.2603\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.6897 - reconstruction_loss: 620.7291 - kl_loss: 11.2637\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 631.5783 - reconstruction_loss: 620.6844 - kl_loss: 11.2815\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.5284 - reconstruction_loss: 620.6393 - kl_loss: 11.2809\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.4726 - reconstruction_loss: 620.5996 - kl_loss: 11.2913\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.4115 - reconstruction_loss: 620.5923 - kl_loss: 11.2940\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.4613 - reconstruction_loss: 620.6011 - kl_loss: 11.2928\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.4011 - reconstruction_loss: 620.5300 - kl_loss: 11.3018\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.4566 - reconstruction_loss: 620.5198 - kl_loss: 11.3152\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.4118 - reconstruction_loss: 620.4796 - kl_loss: 11.3079\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.4751 - reconstruction_loss: 620.4802 - kl_loss: 11.2983\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.3387 - reconstruction_loss: 620.4092 - kl_loss: 11.3205\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 631.3683 - reconstruction_loss: 620.4142 - kl_loss: 11.3253\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.2171 - reconstruction_loss: 620.3765 - kl_loss: 11.3277\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.3442 - reconstruction_loss: 620.3652 - kl_loss: 11.3503\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.2614 - reconstruction_loss: 620.3561 - kl_loss: 11.3224\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.3364 - reconstruction_loss: 620.2922 - kl_loss: 11.3467\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.2542 - reconstruction_loss: 620.3016 - kl_loss: 11.3567\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.2277 - reconstruction_loss: 620.2520 - kl_loss: 11.3519\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0937 - reconstruction_loss: 620.2232 - kl_loss: 11.3627\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.1487 - reconstruction_loss: 620.1986 - kl_loss: 11.3812\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 631.1410 - reconstruction_loss: 620.1955 - kl_loss: 11.3690\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 631.1615 - reconstruction_loss: 620.1448 - kl_loss: 11.3843\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.2142 - reconstruction_loss: 620.1041 - kl_loss: 11.3850\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0506 - reconstruction_loss: 620.0854 - kl_loss: 11.3743\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0915 - reconstruction_loss: 620.0912 - kl_loss: 11.3680\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0575 - reconstruction_loss: 620.0435 - kl_loss: 11.3835\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0170 - reconstruction_loss: 620.0634 - kl_loss: 11.3865\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0010 - reconstruction_loss: 619.9950 - kl_loss: 11.4147\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0581 - reconstruction_loss: 619.9782 - kl_loss: 11.4091\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.9648 - reconstruction_loss: 619.9318 - kl_loss: 11.4138\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 631.0185 - reconstruction_loss: 619.9422 - kl_loss: 11.3941\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 630.9213 - reconstruction_loss: 619.9189 - kl_loss: 11.4122\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.8816 - reconstruction_loss: 619.8768 - kl_loss: 11.4054\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.8954 - reconstruction_loss: 619.8497 - kl_loss: 11.4287\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.7636 - reconstruction_loss: 619.8336 - kl_loss: 11.4233\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.9110 - reconstruction_loss: 619.8237 - kl_loss: 11.4382\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.9890 - reconstruction_loss: 619.8241 - kl_loss: 11.4378\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.8751 - reconstruction_loss: 619.7593 - kl_loss: 11.4528\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.8588 - reconstruction_loss: 619.7527 - kl_loss: 11.4275\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.7908 - reconstruction_loss: 619.7502 - kl_loss: 11.4567\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 4s 6ms/step - loss: 630.7776 - reconstruction_loss: 619.7062 - kl_loss: 11.4627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b6962698eb0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae1 = VAE(encoder, decoder)\n",
    "vae1.compile(optimizer=keras.optimizers.Adam())\n",
    "vae1.fit(dataset, epochs=100, batch_size=100, callbacks=[VAEMonitor(latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f485a52a-f708-4a6f-a51a-bb382a077581",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "f485a52a-f708-4a6f-a51a-bb382a077581",
    "outputId": "98c2fd55-2bec-4c78-b0b1-c88b65d22236"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sampleVae():   \n",
    "    random_latent_vectors = tf.random.normal(shape=(1, 110))\n",
    "    generated_image = vae1.decoder(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    plt.imshow(generated_image[0])\n",
    "    plt.show()\n",
    "\n",
    "sampleVae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9010ff75-8f8d-469e-82d7-bed6eac3af2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: un_trans_conv_vae/assets\n"
     ]
    }
   ],
   "source": [
    "vae1.decoder.save(\"un_trans_conv_vae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234a6e0-a923-4e0a-8bb3-f00fee227122",
   "metadata": {
    "id": "d234a6e0-a923-4e0a-8bb3-f00fee227122",
    "tags": []
   },
   "source": [
    "# Upscaling Convolution Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde0fb0-b0cb-41c7-8a09-8045e031c7c9",
   "metadata": {
    "id": "ddde0fb0-b0cb-41c7-8a09-8045e031c7c9",
    "tags": []
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5462SRIYvA9I",
   "metadata": {
    "id": "5462SRIYvA9I"
   },
   "outputs": [],
   "source": [
    "latent_dim = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "mUJafP7IvBhY",
   "metadata": {
    "id": "mUJafP7IvBhY"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((32, 32, 3)),\n",
    "     \n",
    "        layers.Conv2D(62, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "     \n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((latent_dim,)),\n",
    "        layers.Dense(4 * 4 * latent_dim * 2),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Reshape((4, 4, latent_dim * 2)),\n",
    "     \n",
    "        layers.UpSampling2D(size=(2, 2)),\n",
    "        layers.Conv2D(192, (4, 4), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.UpSampling2D(size=(2, 2)),\n",
    "        layers.Conv2D(96, (4, 4), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.UpSampling2D(size=(2, 2)),   \n",
    "        layers.Conv2D(48, (4, 4), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fMSL7i1qvCwU",
   "metadata": {
    "id": "fMSL7i1qvCwU"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "hW5Unx35vExV",
   "metadata": {
    "id": "hW5Unx35vExV"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                random_latent_vectors = tf.random.normal(shape=(49, 110))\n",
    "                generated_image = gan2.generator(random_latent_vectors)\n",
    "                generated_image.numpy()\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[i])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_ups_conv_gan.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "w6ykyggYvGPA",
   "metadata": {
    "id": "w6ykyggYvGPA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 9s 14ms/step - d_loss: 0.6697 - g_loss: 0.8803\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6859 - g_loss: 0.7884\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6873 - g_loss: 0.7808\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6879 - g_loss: 0.7902\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6842 - g_loss: 0.8023\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6827 - g_loss: 0.8140\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6835 - g_loss: 0.8236\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6830 - g_loss: 0.8170\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6877 - g_loss: 0.7940\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6883 - g_loss: 0.7923\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 8s 12ms/step - d_loss: 0.6874 - g_loss: 0.7941\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6878 - g_loss: 0.7905\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6898 - g_loss: 0.7814\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6910 - g_loss: 0.7725\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6903 - g_loss: 0.7753\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6905 - g_loss: 0.7713\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6907 - g_loss: 0.7681\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6915 - g_loss: 0.7672\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6913 - g_loss: 0.7680\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6908 - g_loss: 0.7686\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 7s 12ms/step - d_loss: 0.6913 - g_loss: 0.7672\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6907 - g_loss: 0.7642\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6911 - g_loss: 0.7656\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6913 - g_loss: 0.7663\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6909 - g_loss: 0.7666\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6912 - g_loss: 0.7661\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6911 - g_loss: 0.7641\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6907 - g_loss: 0.7632\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6904 - g_loss: 0.7671\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6913 - g_loss: 0.7652\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 8s 12ms/step - d_loss: 0.6907 - g_loss: 0.7660\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6900 - g_loss: 0.7697\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6900 - g_loss: 0.7700\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6903 - g_loss: 0.7677\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6894 - g_loss: 0.7687\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6892 - g_loss: 0.7710\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6889 - g_loss: 0.7709\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6883 - g_loss: 0.7723\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6890 - g_loss: 0.7729\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6892 - g_loss: 0.7685\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 7s 12ms/step - d_loss: 0.6886 - g_loss: 0.7719\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6889 - g_loss: 0.7690\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6884 - g_loss: 0.7717\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6888 - g_loss: 0.7672\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6888 - g_loss: 0.7695\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6887 - g_loss: 0.7676\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6885 - g_loss: 0.7707\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6875 - g_loss: 0.7715\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6878 - g_loss: 0.7700\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6878 - g_loss: 0.7728\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 7s 12ms/step - d_loss: 0.6864 - g_loss: 0.7725\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6872 - g_loss: 0.7733\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6871 - g_loss: 0.7742\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6852 - g_loss: 0.7753\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6858 - g_loss: 0.7746\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6843 - g_loss: 0.7771\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6850 - g_loss: 0.7795\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6843 - g_loss: 0.7782\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6850 - g_loss: 0.7768\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6841 - g_loss: 0.7788\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 8s 13ms/step - d_loss: 0.6837 - g_loss: 0.7773\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6844 - g_loss: 0.7823\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6834 - g_loss: 0.7819\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6820 - g_loss: 0.7821\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6825 - g_loss: 0.7809\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6823 - g_loss: 0.7827\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6821 - g_loss: 0.7823\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6819 - g_loss: 0.7834\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6809 - g_loss: 0.7846\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6812 - g_loss: 0.7884\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 7s 12ms/step - d_loss: 0.6816 - g_loss: 0.7861\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6792 - g_loss: 0.7885\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6793 - g_loss: 0.7901\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6778 - g_loss: 0.7916\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6775 - g_loss: 0.7937\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6781 - g_loss: 0.7949\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6764 - g_loss: 0.7948\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6767 - g_loss: 0.8015\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6742 - g_loss: 0.7970\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6740 - g_loss: 0.8032\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 7s 12ms/step - d_loss: 0.6737 - g_loss: 0.8043\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6715 - g_loss: 0.8044\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6725 - g_loss: 0.8115\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6709 - g_loss: 0.8092\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6708 - g_loss: 0.8101\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6684 - g_loss: 0.8161\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6677 - g_loss: 0.8183\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6670 - g_loss: 0.8188\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6651 - g_loss: 0.8223\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6647 - g_loss: 0.8239\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 8s 13ms/step - d_loss: 0.6635 - g_loss: 0.8281\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6625 - g_loss: 0.8301\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6612 - g_loss: 0.8340\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6594 - g_loss: 0.8378\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6582 - g_loss: 0.8401\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6569 - g_loss: 0.8426\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6561 - g_loss: 0.8456\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6548 - g_loss: 0.8490\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6548 - g_loss: 0.8521\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 7s 11ms/step - d_loss: 0.6525 - g_loss: 0.8611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b695ab88310>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gan2 = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan2.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "gan2.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "gydWq37avIsX",
   "metadata": {
    "id": "gydWq37avIsX"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5250594]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def sampleGan():\n",
    "    random_latent_vectors = tf.random.normal(shape=(1, 110))\n",
    "    generated_image = gan2.generator(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    plt.imshow(generated_image[0])\n",
    "    plt.show()\n",
    "    print(gan1.discriminator(generated_image))\n",
    "sampleGan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcSMlyBXvK2Y",
   "metadata": {
    "id": "fcSMlyBXvK2Y"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "def save_plot():\n",
    "    random_latent_vectors = tf.random.normal(shape=(49, 110))\n",
    "    generated_image = gan2.generator(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    for i in range(49):\n",
    "        # define subplot\n",
    "        pyplot.subplot(7, 7, 1 + i)\n",
    "        # turn off axis\n",
    "        pyplot.axis('off')\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(generated_image[i])\n",
    "    # save plot to file\n",
    "    filename = 'generated_plot.png'\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "save_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd140cf8-f1ea-44de-8769-50386b2fc294",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: un_upsc_conv_gan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgan2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mun_upsc_conv_gan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/input_spec.py:196\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;66;03m# Having a shape/dtype is the only commonality of the various tensor-like\u001b[39;00m\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;66;03m# objects that may be passed. The most common kind of invalid type we are\u001b[39;00m\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;66;03m# guarding for is a Layer instance (Functional API), which does not\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# have a `shape` attribute.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    200\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    201\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: un_upsc_conv_gan"
     ]
    }
   ],
   "source": [
    "gan2.generator(\"un_upsc_conv_gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737c17e-f99c-4f93-9014-984d9dc9eb1e",
   "metadata": {
    "id": "b737c17e-f99c-4f93-9014-984d9dc9eb1e",
    "tags": []
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fSS1tEP1wfY0",
   "metadata": {
    "id": "fSS1tEP1wfY0"
   },
   "outputs": [],
   "source": [
    "latent_dim=110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "-UbI0G6cw48W",
   "metadata": {
    "id": "-UbI0G6cw48W"
   },
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(encoder_inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=4, strides=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(8 * 8 * 32, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((8, 8, 32))(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "x = layers.Conv2DTranspose(192, (4, 4), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.UpSampling2D(size=(2, 2))(x)\n",
    "x = layers.Conv2DTranspose(96, (4, 4), padding='same', activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "decoder_outputs = layers.Conv2D(3, (4, 4), padding='same', activation=\"sigmoid\", use_bias=False)(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zY2IDZG0w6Mf",
   "metadata": {
    "id": "zY2IDZG0w6Mf"
   },
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "gCGbM5Qyw9i2",
   "metadata": {
    "id": "gCGbM5Qyw9i2"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "class VAEMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                random_latent_vectors = tf.random.normal(shape=(49, self.latent_dim))\n",
    "                generated_image = vae2.decoder(random_latent_vectors)\n",
    "                generated_image.numpy()\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[0])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_upscs_conv_vae.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "DPaQO-vqw-mO",
   "metadata": {
    "id": "DPaQO-vqw-mO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 8s 12ms/step - loss: 658.4127 - reconstruction_loss: 640.5021 - kl_loss: 11.6475\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 645.1016 - reconstruction_loss: 631.7379 - kl_loss: 12.2064\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 639.2180 - reconstruction_loss: 626.0164 - kl_loss: 12.5506\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 636.5720 - reconstruction_loss: 624.0240 - kl_loss: 12.5373\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 635.5247 - reconstruction_loss: 622.8767 - kl_loss: 12.6670\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 634.6409 - reconstruction_loss: 622.1877 - kl_loss: 12.6941\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 634.0595 - reconstruction_loss: 621.5441 - kl_loss: 12.7136\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 633.4534 - reconstruction_loss: 620.7393 - kl_loss: 12.8570\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 632.6039 - reconstruction_loss: 620.0204 - kl_loss: 12.8965\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 632.2122 - reconstruction_loss: 619.5856 - kl_loss: 12.9018\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 631.8417 - reconstruction_loss: 619.3052 - kl_loss: 12.8547\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 631.7363 - reconstruction_loss: 619.1482 - kl_loss: 12.8811\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 631.5203 - reconstruction_loss: 619.0193 - kl_loss: 12.9102\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 631.4526 - reconstruction_loss: 618.6795 - kl_loss: 13.0085\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 631.1980 - reconstruction_loss: 618.3633 - kl_loss: 13.1175\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 630.8067 - reconstruction_loss: 618.0018 - kl_loss: 13.2183\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 630.7290 - reconstruction_loss: 617.7806 - kl_loss: 13.2706\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 630.6286 - reconstruction_loss: 617.7303 - kl_loss: 13.3294\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 630.3835 - reconstruction_loss: 617.5245 - kl_loss: 13.3648\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 630.3979 - reconstruction_loss: 617.4370 - kl_loss: 13.3695\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 630.3574 - reconstruction_loss: 617.2939 - kl_loss: 13.4214\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 630.2397 - reconstruction_loss: 617.0988 - kl_loss: 13.4671\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 630.1268 - reconstruction_loss: 616.9622 - kl_loss: 13.5413\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.8027 - reconstruction_loss: 616.6295 - kl_loss: 13.6018\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.7074 - reconstruction_loss: 616.4329 - kl_loss: 13.6736\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.5609 - reconstruction_loss: 616.2449 - kl_loss: 13.7052\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 629.4367 - reconstruction_loss: 616.0746 - kl_loss: 13.6947\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 629.3738 - reconstruction_loss: 616.0505 - kl_loss: 13.6895\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.1903 - reconstruction_loss: 615.9853 - kl_loss: 13.6917\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.3792 - reconstruction_loss: 615.9337 - kl_loss: 13.7332\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 629.2543 - reconstruction_loss: 615.8683 - kl_loss: 13.7248\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.2632 - reconstruction_loss: 615.8751 - kl_loss: 13.7243\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.2600 - reconstruction_loss: 615.7977 - kl_loss: 13.7441\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.1183 - reconstruction_loss: 615.7547 - kl_loss: 13.7430\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 629.1628 - reconstruction_loss: 615.7375 - kl_loss: 13.7597\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 629.1243 - reconstruction_loss: 615.6514 - kl_loss: 13.7693\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 629.0640 - reconstruction_loss: 615.6328 - kl_loss: 13.7644\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 6s 10ms/step - loss: 628.9274 - reconstruction_loss: 615.6265 - kl_loss: 13.7755\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.9879 - reconstruction_loss: 615.5966 - kl_loss: 13.7614\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.8057 - reconstruction_loss: 615.5292 - kl_loss: 13.7643\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 628.8211 - reconstruction_loss: 615.5299 - kl_loss: 13.7914\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.9610 - reconstruction_loss: 615.5019 - kl_loss: 13.7926\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.9598 - reconstruction_loss: 615.4653 - kl_loss: 13.7720\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.7961 - reconstruction_loss: 615.3594 - kl_loss: 13.7837\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.8003 - reconstruction_loss: 615.4260 - kl_loss: 13.7991\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.8376 - reconstruction_loss: 615.4035 - kl_loss: 13.8012\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.7560 - reconstruction_loss: 615.3328 - kl_loss: 13.7765\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.7060 - reconstruction_loss: 615.3113 - kl_loss: 13.7935\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.6935 - reconstruction_loss: 615.2875 - kl_loss: 13.8205\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.6150 - reconstruction_loss: 615.2824 - kl_loss: 13.8087\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 628.5661 - reconstruction_loss: 615.2264 - kl_loss: 13.7931\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.6854 - reconstruction_loss: 615.2057 - kl_loss: 13.8451\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.6504 - reconstruction_loss: 615.1548 - kl_loss: 13.8382\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.5911 - reconstruction_loss: 615.1194 - kl_loss: 13.8223\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.5982 - reconstruction_loss: 615.0769 - kl_loss: 13.8689\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.5177 - reconstruction_loss: 615.0311 - kl_loss: 13.8981\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2712 - reconstruction_loss: 614.9189 - kl_loss: 13.9148\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.3172 - reconstruction_loss: 614.8961 - kl_loss: 13.9489\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.3327 - reconstruction_loss: 614.8217 - kl_loss: 13.9593\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.3822 - reconstruction_loss: 614.7842 - kl_loss: 13.9689\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 628.3214 - reconstruction_loss: 614.7383 - kl_loss: 13.9682\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2615 - reconstruction_loss: 614.6951 - kl_loss: 13.9732\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.3384 - reconstruction_loss: 614.6948 - kl_loss: 13.9802\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2125 - reconstruction_loss: 614.7227 - kl_loss: 13.9843\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2777 - reconstruction_loss: 614.6558 - kl_loss: 13.9803\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2414 - reconstruction_loss: 614.6578 - kl_loss: 13.9945\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2259 - reconstruction_loss: 614.5879 - kl_loss: 14.0025\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.1556 - reconstruction_loss: 614.6103 - kl_loss: 13.9842\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.1631 - reconstruction_loss: 614.5614 - kl_loss: 14.0149\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.2426 - reconstruction_loss: 614.5822 - kl_loss: 13.9854\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 628.2149 - reconstruction_loss: 614.5686 - kl_loss: 14.0069\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.1122 - reconstruction_loss: 614.5350 - kl_loss: 14.0020\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.1464 - reconstruction_loss: 614.5303 - kl_loss: 14.0024\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0756 - reconstruction_loss: 614.5094 - kl_loss: 13.9852\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.1667 - reconstruction_loss: 614.4897 - kl_loss: 14.0241\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0651 - reconstruction_loss: 614.4756 - kl_loss: 14.0063\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0974 - reconstruction_loss: 614.4539 - kl_loss: 14.0098\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0584 - reconstruction_loss: 614.4451 - kl_loss: 14.0165\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0310 - reconstruction_loss: 614.4164 - kl_loss: 14.0198\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.9850 - reconstruction_loss: 614.4283 - kl_loss: 14.0018\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 6s 11ms/step - loss: 627.9410 - reconstruction_loss: 614.3933 - kl_loss: 14.0021\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0114 - reconstruction_loss: 614.4031 - kl_loss: 14.0102\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0286 - reconstruction_loss: 614.3831 - kl_loss: 14.0204\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.9323 - reconstruction_loss: 614.3641 - kl_loss: 14.0160\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.9860 - reconstruction_loss: 614.3428 - kl_loss: 14.0461\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.9283 - reconstruction_loss: 614.3536 - kl_loss: 14.0350\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0096 - reconstruction_loss: 614.3508 - kl_loss: 14.0226\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0855 - reconstruction_loss: 614.3303 - kl_loss: 14.0415\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.9932 - reconstruction_loss: 614.3303 - kl_loss: 14.0288\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 628.0176 - reconstruction_loss: 614.2917 - kl_loss: 14.0519\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 7s 11ms/step - loss: 627.9084 - reconstruction_loss: 614.2840 - kl_loss: 14.0398\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8861 - reconstruction_loss: 614.2462 - kl_loss: 14.0385\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8369 - reconstruction_loss: 614.2753 - kl_loss: 14.0347\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8226 - reconstruction_loss: 614.2515 - kl_loss: 14.0333\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.7917 - reconstruction_loss: 614.2548 - kl_loss: 14.0145\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.7936 - reconstruction_loss: 614.2281 - kl_loss: 14.0340\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8838 - reconstruction_loss: 614.2430 - kl_loss: 14.0614\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.7875 - reconstruction_loss: 614.1895 - kl_loss: 14.0298\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8917 - reconstruction_loss: 614.1898 - kl_loss: 14.0495\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 6s 9ms/step - loss: 627.8576 - reconstruction_loss: 614.1795 - kl_loss: 14.0482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2af1bfdc2be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae2 = VAE(encoder, decoder)\n",
    "vae2.compile(optimizer=keras.optimizers.Adam())\n",
    "vae2.fit(dataset, epochs=100, batch_size=100, callbacks=[VAEMonitor(latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "O_yr_Hc9w_8x",
   "metadata": {
    "id": "O_yr_Hc9w_8x"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def sampleVae():   \n",
    "    random_latent_vectors = tf.random.normal(shape=(1, 110))\n",
    "    generated_image = vae2.decoder(random_latent_vectors)\n",
    "    generated_image.numpy()\n",
    "    plt.imshow(generated_image[0])\n",
    "    plt.show()\n",
    "\n",
    "sampleVae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a5258dd-7263-431c-a49a-87d253cf3b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:05:38.477541: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: un_upsc_conv_vae/assets\n"
     ]
    }
   ],
   "source": [
    "vae2.decoder.save(\"un_upsc_conv_vae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e14104-c248-4bec-a348-b75ba19fb637",
   "metadata": {
    "id": "b2e14104-c248-4bec-a348-b75ba19fb637",
    "tags": []
   },
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b5c2c77-c365-4e0a-bf96-5f39d4c5b927",
   "metadata": {
    "id": "3b5c2c77-c365-4e0a-bf96-5f39d4c5b927",
    "outputId": "f2641651-4242-40de-a37f-0404ff9c8d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (60000, 32, 32, 3)\n",
      "Shape of training labels: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# We'll use all the available examples from both the training and test\n",
    "# sets.\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "all_images = np.concatenate([x_train, x_test])\n",
    "all_labels = np.concatenate([y_train, y_test])\n",
    "\n",
    "# Scale the pixel values to [0, 1] range, add a channel dimension to\n",
    "# the images, and one-hot encode the labels.\n",
    "all_images = all_images.astype(\"float32\") / 255.0\n",
    "all_labels = keras.utils.to_categorical(all_labels, 10)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "print(f\"Shape of training images: {all_images.shape}\")\n",
    "print(f\"Shape of training labels: {all_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e034c5-20bf-462f-948e-4186def41e3f",
   "metadata": {
    "id": "49e034c5-20bf-462f-948e-4186def41e3f",
    "tags": []
   },
   "source": [
    "# Conditional Transposed Convolution Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe2149-a956-490e-9b91-0e0e638be83f",
   "metadata": {
    "id": "cefe2149-a956-490e-9b91-0e0e638be83f",
    "tags": []
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0540d655-26e7-4ab5-a0c0-90220179d34d",
   "metadata": {
    "id": "0540d655-26e7-4ab5-a0c0-90220179d34d"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "image_size = 32\n",
    "latent_dim = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abb1d44-9677-4713-ae59-3e93025874df",
   "metadata": {
    "id": "4abb1d44-9677-4713-ae59-3e93025874df",
    "outputId": "67132eca-88ce-4d66-a4e9-fd695100a66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 13\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73d483b-77fb-44be-82d6-742970e3f24a",
   "metadata": {
    "id": "c73d483b-77fb-44be-82d6-742970e3f24a"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((32, 32, discriminator_in_channels)),\n",
    "     \n",
    "        layers.Conv2D(62, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "\n",
    "        layers.Dense(4 * 4 * generator_in_channels * 2),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Reshape((4, 4, generator_in_channels * 2)),\n",
    "     \n",
    "        tf.keras.layers.Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "\n",
    "        tf.keras.layers.Conv2DTranspose(96, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        \n",
    "        tf.keras.layers.Conv2DTranspose(48, (4, 4), strides=(2, 2), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "     \n",
    "        layers.Conv2DTranspose(3, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d72333c-f4c9-4dc5-966d-bc6798cf7692",
   "metadata": {
    "id": "7d72333c-f4c9-4dc5-966d-bc6798cf7692"
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        \n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1bd4f3-c923-4720-ba50-27e3ed5e9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "class CGANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                trained_gen = cond_gan.generator\n",
    "                noise = tf.random.normal(shape=(1, latent_dim))\n",
    "                label = keras.utils.to_categorical([random.randint(0, 9)], 10)\n",
    "                noise_and_labels = tf.concat([noise, label], 1)\n",
    "                generated_image = trained_gen.predict(noise_and_labels)\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[0])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_cond_trans_conv_gan.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a708e94-12b0-445d-9827-f51e9c591138",
   "metadata": {
    "id": "7a708e94-12b0-445d-9827-f51e9c591138",
    "outputId": "b2fdace0-f5a0-4175-d511-0ab1021ff622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 8s 11ms/step - g_loss: 1.0027 - d_loss: 0.6223\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.9254 - d_loss: 0.6568\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8400 - d_loss: 0.6785\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8393 - d_loss: 0.6753\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8274 - d_loss: 0.6751\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8486 - d_loss: 0.6691\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8465 - d_loss: 0.6700\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8594 - d_loss: 0.6691\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8531 - d_loss: 0.6742\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8437 - d_loss: 0.6736\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8371 - d_loss: 0.6771\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8289 - d_loss: 0.6767\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8245 - d_loss: 0.6802\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8331 - d_loss: 0.6803\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8162 - d_loss: 0.6779\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8153 - d_loss: 0.6819\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8210 - d_loss: 0.6783\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8158 - d_loss: 0.6796\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8099 - d_loss: 0.6825\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.8098 - d_loss: 0.6823\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7949 - d_loss: 0.6824\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7957 - d_loss: 0.6839\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7919 - d_loss: 0.6845\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7958 - d_loss: 0.6843\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7868 - d_loss: 0.6853\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7876 - d_loss: 0.6862\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7869 - d_loss: 0.6864\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7841 - d_loss: 0.6858\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7856 - d_loss: 0.6858\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7790 - d_loss: 0.6869\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7843 - d_loss: 0.6877\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7769 - d_loss: 0.6874\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7804 - d_loss: 0.6854\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7803 - d_loss: 0.6872\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7741 - d_loss: 0.6870\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7742 - d_loss: 0.6872\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7745 - d_loss: 0.6861\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7736 - d_loss: 0.6881\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7727 - d_loss: 0.6883\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7710 - d_loss: 0.6876\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7733 - d_loss: 0.6884\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7728 - d_loss: 0.6886\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7720 - d_loss: 0.6884\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7678 - d_loss: 0.6890\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7702 - d_loss: 0.6896\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7679 - d_loss: 0.6885\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7648 - d_loss: 0.6886\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7703 - d_loss: 0.6874\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7691 - d_loss: 0.6891\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7668 - d_loss: 0.6889\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 7s 12ms/step - g_loss: 0.7671 - d_loss: 0.6878\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7681 - d_loss: 0.6891\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7674 - d_loss: 0.6881\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7686 - d_loss: 0.6889\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7652 - d_loss: 0.6896\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7640 - d_loss: 0.6898\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7662 - d_loss: 0.6884\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7667 - d_loss: 0.6891\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7628 - d_loss: 0.6889\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7642 - d_loss: 0.6894\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7654 - d_loss: 0.6886\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7662 - d_loss: 0.6885\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7651 - d_loss: 0.6887\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7658 - d_loss: 0.6891\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7631 - d_loss: 0.6893\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7650 - d_loss: 0.6890\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7669 - d_loss: 0.6889\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7643 - d_loss: 0.6888\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7662 - d_loss: 0.6890\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7648 - d_loss: 0.6885\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7666 - d_loss: 0.6889\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7655 - d_loss: 0.6880\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7637 - d_loss: 0.6886\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7647 - d_loss: 0.6880\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7680 - d_loss: 0.6874\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7649 - d_loss: 0.6887\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7627 - d_loss: 0.6902\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7648 - d_loss: 0.6881\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7677 - d_loss: 0.6876\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7652 - d_loss: 0.6872\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 7s 12ms/step - g_loss: 0.7648 - d_loss: 0.6880\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7666 - d_loss: 0.6867\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7693 - d_loss: 0.6868\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7669 - d_loss: 0.6871\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7668 - d_loss: 0.6870\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7704 - d_loss: 0.6861\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7683 - d_loss: 0.6860\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7695 - d_loss: 0.6864\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7713 - d_loss: 0.6860\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7703 - d_loss: 0.6859\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7715 - d_loss: 0.6855\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7716 - d_loss: 0.6851\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7739 - d_loss: 0.6853\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7721 - d_loss: 0.6845\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7716 - d_loss: 0.6851\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7721 - d_loss: 0.6846\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7722 - d_loss: 0.6849\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7717 - d_loss: 0.6844\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7739 - d_loss: 0.6835\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 5s 8ms/step - g_loss: 0.7801 - d_loss: 0.6837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aff8e1866a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "cond_gan.fit(dataset, epochs=100, callbacks=[CGANMonitor(latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebf70e4-5f9b-4883-b9f3-b81291877d38",
   "metadata": {
    "id": "9ebf70e4-5f9b-4883-b9f3-b81291877d38"
   },
   "outputs": [],
   "source": [
    "def sampleCondGan(class_num):\n",
    "    trained_gen = cond_gan.generator\n",
    "    noise = tf.random.normal(shape=(1, latent_dim))\n",
    "    label = keras.utils.to_categorical([class_num], 10)\n",
    "    noise_and_labels = tf.concat([noise, label], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    plt.imshow(fake[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e0b8107-ef7f-4662-85ce-af468c7c31f3",
   "metadata": {
    "id": "6e0b8107-ef7f-4662-85ce-af468c7c31f3",
    "outputId": "23a16f1c-0fab-42d4-d051-958576aa9465"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleCondGan(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4efc951-7bc1-4d8c-8f5e-81b34cfcc913",
   "metadata": {
    "id": "b4efc951-7bc1-4d8c-8f5e-81b34cfcc913",
    "outputId": "7dc7f6dc-8289-43da-b31c-b3b322dc875c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: trans-cond-gan/assets\n"
     ]
    }
   ],
   "source": [
    "cond_gan.generator.save(\"trans-cond-gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b6a0d9-351a-46d6-9068-609f645ab9fa",
   "metadata": {
    "id": "62b6a0d9-351a-46d6-9068-609f645ab9fa",
    "tags": []
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643fcd97-fbb3-45c2-b663-a69e6fe9f28a",
   "metadata": {
    "id": "643fcd97-fbb3-45c2-b663-a69e6fe9f28a"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "image_size = 32\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c503f8-e4df-4dec-af77-3a2c0a0669c2",
   "metadata": {
    "id": "b5c503f8-e4df-4dec-af77-3a2c0a0669c2",
    "outputId": "9569db06-0444-48f7-f719-519a7bb5fb47"
   },
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e1948-59dc-426f-8300-d141da829cc4",
   "metadata": {
    "id": "be1e1948-59dc-426f-8300-d141da829cc4"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=((32, 32, discriminator_in_channels))),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            # No activation\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            tf.keras.layers.Reshape(target_shape=(latent_dim * 2,)),\n",
    "        ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim + num_classes,)),\n",
    "            tf.keras.layers.Dense(units=8*8*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(8, 8, 32)),  \n",
    "\n",
    "            tf.keras.layers.Conv2DTranspose(192, (4, 4), strides=(2, 2), padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.Conv2DTranspose(96, (4, 4), strides=(2, 2), padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2D(3, (4, 4), padding='same', use_bias=False)\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6dc1d-ab7a-4ef1-bf02-8bdc40b6fa64",
   "metadata": {
    "id": "95d6dc1d-ab7a-4ef1-bf02-8bdc40b6fa64"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x, real, one_hot_labels):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    z_comb = tf.concat([z, one_hot_labels], 1)\n",
    "    x_logit = model.decode(z_comb)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=real)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, batch, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    real_images, one_hot_labels = batch\n",
    "\n",
    "\n",
    "    image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "    image_one_hot_labels = tf.repeat(\n",
    "      image_one_hot_labels, repeats=[image_size * image_size]\n",
    "    )\n",
    "    image_one_hot_labels = tf.reshape(\n",
    "      image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "    )\n",
    "    X = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, X, real_images, one_hot_labels)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810137fc-2dcd-4262-b589-f35a48fa6778",
   "metadata": {
    "id": "810137fc-2dcd-4262-b589-f35a48fa6778"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 110\n",
    "\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8397b8f-0a50-46a9-a5b9-b060fffa1b44",
   "metadata": {
    "id": "c8397b8f-0a50-46a9-a5b9-b060fffa1b44",
    "outputId": "66c84467-28d7-47db-a930-a02928e8120c"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for batch in dataset: \n",
    "        train_step(model, batch, optimizer)\n",
    "    end_time = time.time()\n",
    "    print('Epoch: {}, time elapse for current epoch: {}'\n",
    "    .format(epoch, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3ff30-4e0e-45d8-958e-68475b394f9a",
   "metadata": {
    "id": "96f3ff30-4e0e-45d8-958e-68475b394f9a"
   },
   "outputs": [],
   "source": [
    "def sampleCondVae():\n",
    "    z = tf.random.normal(shape=(1, latent_dim))\n",
    "    conditioned_array = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    conditioned_array = np.expand_dims(conditioned_array, axis=0)\n",
    "    z_comb = tf.concat([z, conditioned_array], 1)\n",
    "    picture = model.sample(z_comb)[0]\n",
    "    plt.imshow(picture)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad963c-8c59-485e-ad2c-b01ea194de13",
   "metadata": {
    "id": "a4ad963c-8c59-485e-ad2c-b01ea194de13",
    "outputId": "fc59d59b-2f4d-4469-d2bc-78ae39a39723"
   },
   "outputs": [],
   "source": [
    "sampleCondVae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a5dc5-661f-4a8b-a14d-966a7b8e5dba",
   "metadata": {
    "id": "9b6a5dc5-661f-4a8b-a14d-966a7b8e5dba",
    "outputId": "3b1fae91-e45d-4bc6-8d51-b0a735f25e18"
   },
   "outputs": [],
   "source": [
    "model.decoder.save(\"trans-cond-vae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f9506-dbe0-4b31-a6c1-557d6ec33d94",
   "metadata": {
    "id": "7c6f9506-dbe0-4b31-a6c1-557d6ec33d94",
    "tags": []
   },
   "source": [
    "# Conditional Upscaling Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad89b80-e247-4747-b19e-754f18a7ac97",
   "metadata": {
    "id": "6ad89b80-e247-4747-b19e-754f18a7ac97",
    "tags": []
   },
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565f7391-9af2-49f3-98f6-831e3f3822f7",
   "metadata": {
    "id": "565f7391-9af2-49f3-98f6-831e3f3822f7"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "image_size = 32\n",
    "latent_dim = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cea779-2e3c-4212-9952-de3f831fcc3e",
   "metadata": {
    "id": "66cea779-2e3c-4212-9952-de3f831fcc3e",
    "outputId": "4caa7dea-813e-4f77-f8a9-1458bc94fb7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 13\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e69a0f-2a4b-4c5c-bb59-3655a0423fca",
   "metadata": {
    "id": "e2e69a0f-2a4b-4c5c-bb59-3655a0423fca"
   },
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((32, 32, discriminator_in_channels)),\n",
    "\n",
    "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "        # We want to generate 128 + num_classes coefficients to reshape into a\n",
    "        # 7x7x(128 + num_classes) map.\n",
    "        layers.Dense(4 * 4 * generator_in_channels * 2),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Reshape((4, 4, generator_in_channels * 2)),\n",
    "     \n",
    "        layers.UpSampling2D(size=(2, 2)),\n",
    "        layers.Conv2D(192, (4, 4), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "\n",
    "\n",
    "        layers.UpSampling2D(size=(2, 2)),\n",
    "        layers.Conv2D(96, (4, 4), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.UpSampling2D(size=(2, 2)),\n",
    "        layers.Conv2D(48, (4, 4), padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "     \n",
    "        layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc3bfbd0-ab82-4eee-8b80-69f210751d3a",
   "metadata": {
    "id": "bc3bfbd0-ab82-4eee-8b80-69f210751d3a"
   },
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[image_size * image_size]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227702d4-3a79-4cdd-a9f0-7100970133fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import random\n",
    "class CGANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if(epoch % 10 == 0):\n",
    "            for i in range(49):\n",
    "                trained_gen = cond_gan1.generator\n",
    "                noise = tf.random.normal(shape=(1, latent_dim))\n",
    "                label = keras.utils.to_categorical([random.randint(0, 9)], 10)\n",
    "                noise_and_labels = tf.concat([noise, label], 1)\n",
    "                generated_image = trained_gen.predict(noise_and_labels)\n",
    "                # define subplot\n",
    "                pyplot.subplot(7, 7, 1 + i)\n",
    "                # turn off axis\n",
    "                pyplot.axis('off')\n",
    "                # plot raw pixel data\n",
    "                pyplot.imshow(generated_image[0])\n",
    "            # save plot to file\n",
    "            filename = \"generated_img_%03d_cond_upsc_conv_gan.png\" % (epoch)\n",
    "            pyplot.savefig(filename)\n",
    "            pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b719c4-21e9-4d9b-8d38-60a311a1b3e9",
   "metadata": {
    "id": "c2b719c4-21e9-4d9b-8d38-60a311a1b3e9",
    "outputId": "429523d6-45f2-486a-c2da-7898fdae5ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 10s 15ms/step - g_loss: 0.8502 - d_loss: 0.6788\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8223 - d_loss: 0.6804\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8077 - d_loss: 0.6821\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8104 - d_loss: 0.6828\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8132 - d_loss: 0.6851\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8107 - d_loss: 0.6844\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8107 - d_loss: 0.6842\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8033 - d_loss: 0.6881\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7916 - d_loss: 0.6866\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7923 - d_loss: 0.6874\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 9s 15ms/step - g_loss: 0.7892 - d_loss: 0.6875\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7867 - d_loss: 0.6882\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7899 - d_loss: 0.6889\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7911 - d_loss: 0.6885\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7832 - d_loss: 0.6884\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7826 - d_loss: 0.6843\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7811 - d_loss: 0.6880\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7857 - d_loss: 0.6877\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7852 - d_loss: 0.6864\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7828 - d_loss: 0.6870\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 9s 15ms/step - g_loss: 0.7843 - d_loss: 0.6869\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7833 - d_loss: 0.6865\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7842 - d_loss: 0.6857\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7809 - d_loss: 0.6864\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7843 - d_loss: 0.6865\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7794 - d_loss: 0.6871\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7788 - d_loss: 0.6860\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7858 - d_loss: 0.6845\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7844 - d_loss: 0.6863\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7878 - d_loss: 0.6843\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 9s 14ms/step - g_loss: 0.7824 - d_loss: 0.6848\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7898 - d_loss: 0.6836\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7894 - d_loss: 0.6829\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7908 - d_loss: 0.6828\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7872 - d_loss: 0.6807\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7911 - d_loss: 0.6820\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7924 - d_loss: 0.6799\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7962 - d_loss: 0.6792\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.7996 - d_loss: 0.6781\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8019 - d_loss: 0.6763\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 9s 15ms/step - g_loss: 0.8034 - d_loss: 0.6759\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8043 - d_loss: 0.6752\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8149 - d_loss: 0.6746\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8097 - d_loss: 0.6730\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8123 - d_loss: 0.6718\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8188 - d_loss: 0.6711\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8217 - d_loss: 0.6690\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8249 - d_loss: 0.6674\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8265 - d_loss: 0.6652\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8402 - d_loss: 0.6631\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 9s 14ms/step - g_loss: 0.8414 - d_loss: 0.6617\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8487 - d_loss: 0.6586\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8507 - d_loss: 0.6557\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8596 - d_loss: 0.6567\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8687 - d_loss: 0.6538\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8686 - d_loss: 0.6511\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8756 - d_loss: 0.6507\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8760 - d_loss: 0.6483\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8770 - d_loss: 0.6481\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.8762 - d_loss: 0.6543\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 9s 15ms/step - g_loss: 0.8891 - d_loss: 0.6424\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9041 - d_loss: 0.6408\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9014 - d_loss: 0.6396\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9105 - d_loss: 0.6366\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9213 - d_loss: 0.6361\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9252 - d_loss: 0.6318\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9296 - d_loss: 0.6303\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9406 - d_loss: 0.6272\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9513 - d_loss: 0.6253\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9534 - d_loss: 0.6214\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 9s 14ms/step - g_loss: 0.9625 - d_loss: 0.6199\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9715 - d_loss: 0.6184\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9695 - d_loss: 0.6151\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9832 - d_loss: 0.6119\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 0.9915 - d_loss: 0.6117\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0030 - d_loss: 0.6043\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0055 - d_loss: 0.6033\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0218 - d_loss: 0.6010\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0235 - d_loss: 0.6006\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0300 - d_loss: 0.5969\n",
      "Epoch 81/100\n",
      "600/600 [==============================] - 9s 14ms/step - g_loss: 1.0394 - d_loss: 0.5951\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0487 - d_loss: 0.5906\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0613 - d_loss: 0.5927\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0731 - d_loss: 0.5883\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0733 - d_loss: 0.5840\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.0840 - d_loss: 0.5828\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1019 - d_loss: 0.5806\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1115 - d_loss: 0.5768\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1182 - d_loss: 0.5737\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1254 - d_loss: 0.5690\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 9s 15ms/step - g_loss: 1.1355 - d_loss: 0.5673\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1358 - d_loss: 0.5697\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1516 - d_loss: 0.5634\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1724 - d_loss: 0.5626\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1734 - d_loss: 0.5572\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1891 - d_loss: 0.5547\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.1935 - d_loss: 0.5513\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.2161 - d_loss: 0.5493\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.2278 - d_loss: 0.5470\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 7s 11ms/step - g_loss: 1.2257 - d_loss: 0.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b5dabf9f9a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_gan1 = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan1.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "cond_gan1.fit(dataset, epochs=100, callbacks=[CGANMonitor(latent_dim=latent_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db74e5-e06d-49d7-9614-fbb0c25123c0",
   "metadata": {
    "id": "33db74e5-e06d-49d7-9614-fbb0c25123c0"
   },
   "outputs": [],
   "source": [
    "def sampleCondGan(class_num):\n",
    "    trained_gen = cond_gan1.generator\n",
    "    noise = tf.random.normal(shape=(1, latent_dim))\n",
    "    label = keras.utils.to_categorical([class_num], 10)\n",
    "    noise_and_labels = tf.concat([noise, label], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)\n",
    "    plt.imshow(fake[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b597c80-136c-466b-bffb-e4072c47d6c3",
   "metadata": {
    "id": "2b597c80-136c-466b-bffb-e4072c47d6c3",
    "outputId": "01eb1492-16ba-4d3b-c7d4-c626f6953f6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleCondGan(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34febeda-00a8-4f14-a4ba-4048a70e98f0",
   "metadata": {
    "id": "34febeda-00a8-4f14-a4ba-4048a70e98f0",
    "outputId": "14c21108-17d1-4c97-b310-9829efcb525d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: upsc-cond-gan/assets\n"
     ]
    }
   ],
   "source": [
    "cond_gan1.generator.save(\"upsc-cond-gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbae74-d38f-4c36-ab2a-b78c6869001f",
   "metadata": {
    "id": "79cbae74-d38f-4c36-ab2a-b78c6869001f",
    "tags": []
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9baf0-952c-4130-bb84-7b95296a271f",
   "metadata": {
    "id": "d8c9baf0-952c-4130-bb84-7b95296a271f"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3\n",
    "num_classes = 10\n",
    "image_size = 32\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a807f7-8572-44ec-a2a8-a0d17edde49e",
   "metadata": {
    "id": "b8a807f7-8572-44ec-a2a8-a0d17edde49e",
    "outputId": "4b01df96-6ee8-4f49-f164-b5ab0e3a9b9e"
   },
   "outputs": [],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfe18b-183e-4ca5-b659-da7ae5fd4329",
   "metadata": {
    "id": "32bfe18b-183e-4ca5-b659-da7ae5fd4329"
   },
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "    \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=((32, 32, discriminator_in_channels))),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=4, strides=(2, 2), activation='relu'),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "\n",
    "            # No activation\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            tf.keras.layers.Reshape(target_shape=(latent_dim * 2,)),\n",
    "        ]\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim + num_classes,)),\n",
    "            tf.keras.layers.Dense(units=8*8*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(8, 8, 32)),  \n",
    "\n",
    "            tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
    "            tf.keras.layers.Conv2D(192, (4, 4), padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
    "            tf.keras.layers.Conv2D(96, (4, 4), padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2D(3, (4, 4), padding='same', use_bias=False)\n",
    "        ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(1, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bb94d9-b382-419a-85fa-b67e34785924",
   "metadata": {
    "id": "75bb94d9-b382-419a-85fa-b67e34785924"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x, real, one_hot_labels):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    z_comb = tf.concat([z, one_hot_labels], 1)\n",
    "    x_logit = model.decode(z_comb)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=real)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, batch, optimizer):\n",
    "    \"\"\"Executes one training step and returns the loss.\n",
    "\n",
    "    This function computes the loss and gradients, and uses the latter to\n",
    "    update the model's parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    real_images, one_hot_labels = batch\n",
    "\n",
    "\n",
    "    image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "    image_one_hot_labels = tf.repeat(\n",
    "      image_one_hot_labels, repeats=[image_size * image_size]\n",
    "    )\n",
    "    image_one_hot_labels = tf.reshape(\n",
    "      image_one_hot_labels, (-1, image_size, image_size, num_classes)\n",
    "    )\n",
    "    X = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, X, real_images, one_hot_labels)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e371f7-0305-416d-813c-1f31792b53f7",
   "metadata": {
    "id": "e3e371f7-0305-416d-813c-1f31792b53f7"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 110\n",
    "\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42240f7f-5885-4ec2-9c66-3ac846bf94e8",
   "metadata": {
    "id": "42240f7f-5885-4ec2-9c66-3ac846bf94e8",
    "outputId": "5866b92f-9a9a-48bc-ef9b-2a6f4b4114c0"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for batch in dataset: \n",
    "        train_step(model, batch, optimizer)\n",
    "    end_time = time.time()\n",
    "    print('Epoch: {}, time elapse for current epoch: {}'\n",
    "    .format(epoch, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3395700b-2465-4b3c-bf68-4f28d28e5736",
   "metadata": {
    "id": "3395700b-2465-4b3c-bf68-4f28d28e5736"
   },
   "outputs": [],
   "source": [
    "def sampleCondVae():\n",
    "    z = tf.random.normal(shape=(1, latent_dim))\n",
    "    conditioned_array = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    conditioned_array = np.expand_dims(conditioned_array, axis=0)\n",
    "    z_comb = tf.concat([z, conditioned_array], 1)\n",
    "    picture = model.sample(z_comb)[0]\n",
    "    plt.imshow(picture)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fc9164-4939-429a-8188-c5493a785453",
   "metadata": {
    "id": "31fc9164-4939-429a-8188-c5493a785453",
    "outputId": "b67e591a-f07e-4862-c5d2-21df41271a38"
   },
   "outputs": [],
   "source": [
    "sampleCondVae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de5151-f51f-4afb-a81a-eb283be199cb",
   "metadata": {
    "id": "70de5151-f51f-4afb-a81a-eb283be199cb",
    "outputId": "09267611-52cb-4a8f-b7f1-c5ff817ccdad"
   },
   "outputs": [],
   "source": [
    "model.decoder.save(\"upsc-cond-vae\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ddde0fb0-b0cb-41c7-8a09-8045e031c7c9"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
